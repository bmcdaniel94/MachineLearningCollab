{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"question_4_parkinsons_exam_question.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xa3MVOOk0Oag","colab_type":"code","outputId":"ae36b46a-ffad-4d68-ad43-ea504fd44413","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1586185713878,"user_tz":300,"elapsed":222,"user":{"displayName":"Benjamin McDaniel","photoUrl":"","userId":"17960085804568781582"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from  google.colab  import  drive\n","from sklearn.model_selection import LeaveOneOut\n","\n","drive.mount('/content/gdrive')\n","mydirectory = 'gdrive/My Drive/Colab Notebooks/PD/'\n","\n","#Parkinson's dataset is downloaded from UCI ML repository: https://archive.ics.uci.edu/ml/datasets/parkinsons\n","fname = mydirectory + \"parkinsons.data\"       #195 rows/recordings, there are only 32 human subjects (8 of which are PD)\n","data = pd.read_csv(fname)                     #6 recordings per subject (7 recordings for only 3 of the subjects)\n","dataX = data.drop(columns=['status','name'])  #We have 6records*29subj + 7records*3subjects = 195\n","\n","\n","logo = LeaveOneOut()\n","\n","logo.get_n_splits(dataX)\n","#print the first few rows\n","print(data)\n","#print(logo)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  ...   spread2        D2       PPE\n","0    phon_R01_S01_1      119.992       157.302  ...  0.266482  2.301442  0.284654\n","1    phon_R01_S01_2      122.400       148.650  ...  0.335590  2.486855  0.368674\n","2    phon_R01_S01_3      116.682       131.111  ...  0.311173  2.342259  0.332634\n","3    phon_R01_S01_4      116.676       137.871  ...  0.334147  2.405554  0.368975\n","4    phon_R01_S01_5      116.014       141.781  ...  0.234513  2.332180  0.410335\n","..              ...          ...           ...  ...       ...       ...       ...\n","190  phon_R01_S50_2      174.188       230.978  ...  0.121952  2.657476  0.133050\n","191  phon_R01_S50_3      209.516       253.017  ...  0.129303  2.784312  0.168895\n","192  phon_R01_S50_4      174.688       240.005  ...  0.158453  2.679772  0.131728\n","193  phon_R01_S50_5      198.764       396.961  ...  0.207454  2.138608  0.123306\n","194  phon_R01_S50_6      214.289       260.277  ...  0.190667  2.555477  0.148569\n","\n","[195 rows x 24 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vIzib4zvUf40","colab_type":"code","outputId":"4863105a-cfb9-48f7-d6f4-7cd17e853242","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1586185716421,"user_tz":300,"elapsed":1152,"user":{"displayName":"Benjamin McDaniel","photoUrl":"","userId":"17960085804568781582"}}},"source":["#FIRST ATTEMPT\n","#NOTE THAT THIS IS NOT A GOOD FIT WITH THE DATASET, WE NEED LEAVE SUBJECT OUT INSTEAD\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","\n","# Split the dataset in two equal parts\n","X_train, X_test, y_train, y_test = train_test_split(dataX, data['status'], test_size=0.5, random_state=0)       #prev dataX\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)   #ranges, mean, stddev of the features in the training set\n","X_test = scaler.transform(X_test) \n","#especially if you are going to use rbf-svm, this preprocessing step is very important\n","#because SVM will be calculateing the distance of the test example to each one of the training examples\n","#you dont want to have one feature ranging 100 to 200 and the other one (which is perhaps more important) ranging from 0 to 1\n","#Refer to the discussion in the next code cell about what normalization is.\n","\n","\n","\n","#Now, we start training-optimizing-testing the classifier\n","#Find the optimal parameters by cross-validation, well, optimal only if you do a proper cross-validation\n","tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-1, 1, 10, 100],   #libsvm showed that each point has some influence around itself in the space\n","                     #gamma is the inverse of the sigma of the \"sphere\"  (the mean of that sphere is on that particular training example)\n","                     'C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]},\n","                    {'kernel': ['linear'], 'C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]}]\n","\n","clf = GridSearchCV(SVC(), tuned_parameters, scoring='f1_macro')  #accuracy can be bad for this dataset because it is imbalanced, we have a lot more Parkinson's subjects.\n","#Here is the summary of the lecture on why the dataset is imbalanced, thus forcing us to use average of f1 scores of the classes. \n","#Keep in mind the study is for telediagnosis of Parkinson's (a good story for COVID-19 era). \n","#A good control group is needed, unfortunately we have only 8 healthy subjects.\n","#In the video I explained why that might be in more detail, the main idea is that finding a good control group (vs Parkinson's) is not easy. \n","#You cannot use students as a control group because normally they are not going to be the calling the telediagnosis service to be tested for Parkinsonism. \n","#It is important to match demographic groups etc.\n","\n","\n","clf.fit(X_train, y_train)\n","print(\"Best parameters set found on development set:\",clf.best_params_)\n","y_pred = clf.predict(X_test)\n","print(classification_report(y_test, y_pred))\n","\n","#WOW, we get 91% accuracy\n","#THAT 91% IS NOT REALISTIC THOUGH!  I EXPLAINED WHY IN THE VIDEO."],"execution_count":14,"outputs":[{"output_type":"stream","text":["Best parameters set found on development set: {'C': 2, 'gamma': 0.1, 'kernel': 'rbf'}\n","              precision    recall  f1-score   support\n","\n","           0       0.94      0.67      0.78        24\n","           1       0.90      0.99      0.94        74\n","\n","    accuracy                           0.91        98\n","   macro avg       0.92      0.83      0.86        98\n","weighted avg       0.91      0.91      0.90        98\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IVIiPyotWd1X","colab_type":"code","outputId":"7c810a59-0bc0-4170-ce11-c8cc292adf69","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1586185718773,"user_tz":300,"elapsed":200,"user":{"displayName":"Benjamin McDaniel","photoUrl":"","userId":"17960085804568781582"}}},"source":["#A LITTLE DISCUSSION ABOUT WHAT NORMALIZATION IS:\n","#zero centered and unit standard deviation\n","\n","X_normalized = scaler.fit_transform(dataX)   #ranges, mean, stddev etc of the features in the training set       dataX\n","print('original vs normalized values for the first feature, first 10 rows are shown:')\n","print(np.concatenate((X_normalized[:10,[0]],dataX.iloc[:10,[0]]), axis=1)) #dataX\n","print('\\nX_normalized\\n')\n","print(X_normalized[:10,0])\n","print('\\ndataX.iloc\\n')\n","print(dataX.iloc[:10,0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["original vs normalized values for the first feature, first 10 rows are shown:\n","[[ -0.82929965 119.992     ]\n"," [ -0.77097169 122.4       ]\n"," [ -0.90947638 116.682     ]\n"," [ -0.90962172 116.676     ]\n"," [ -0.92565706 116.014     ]\n"," [ -0.81573501 120.552     ]\n"," [ -0.82263845 120.267     ]\n"," [ -1.13595747 107.332     ]\n"," [ -1.4169878   95.73      ]\n"," [ -1.43331382  95.056     ]]\n","\n","X_normalized\n","\n","[-0.82929965 -0.77097169 -0.90947638 -0.90962172 -0.92565706 -0.81573501\n"," -0.82263845 -1.13595747 -1.4169878  -1.43331382]\n","\n","dataX.iloc\n","\n","0    119.992\n","1    122.400\n","2    116.682\n","3    116.676\n","4    116.014\n","5    120.552\n","6    120.267\n","7    107.332\n","8     95.730\n","9     95.056\n","Name: MDVP:Fo(Hz), dtype: float64\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"swL4zrLCuly3","colab_type":"code","outputId":"abd68427-5e24-4d4c-847c-162f166b9878","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1586186108400,"user_tz":300,"elapsed":503,"user":{"displayName":"Benjamin McDaniel","photoUrl":"","userId":"17960085804568781582"}}},"source":["from sklearn.model_selection import LeaveOneGroupOut\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import classification_report\n","\n","print('N_subjects', logo.get_n_splits(dataX, data['status'],data['name'].astype(str).str[:-2]))\n","\n","groups = dataX\n","logo = LeaveOneGroupOut()\n","#logo = LeaveOneOut()\n","y=dataX.iloc\n","\n","logo.get_n_splits(dataX, y, groups)\n","\n","#SPLIT INDIVIDUALS\n","trains = []\n","tests = []\n","N_train = 0\n","\n","def LeaveOneGroupOut():\n","  for train_index, test_index in logo.split(dataX, data['status'],data['name'].astype(str).str[:-2]):\n","      if (np.random.random() > 0.25) :\n","          trains=np.append(trains, test_index)\n","          N_train=N_train+1\n","      else :\n","          tests=np.append(tests, test_index)\n","\n","X_train, X_test = dataX.iloc[trains,:], dataX.iloc[tests,:]\n","y_train, y_test = data['status'][trains], data['status'][tests]\n","\n","# Set the parameters by cross-validation\n","tuned_parameters = [{'svm__kernel': ['rbf'], 'svm__gamma': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100],\n","                     'svm__C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]},\n","                    {'svm__kernel': ['linear'], 'svm__C': [0.25, 0.5, 1, 2, 4, 8, 16, 32]}]\n","\n","print(trains)\n","\n","\n","\n","#from sklearn.pipeline import Pipeline\n","#pipeline = Pipeline([('scale',StandardScaler()), ('svm',SVC())])\n","\n","#CROSS VALIDATION IN GRIDSEARCH BELOW IS NOT USING LEAVE SUBJECT OUT, IT USES THE STANDARD K-FOLD\n","#THAT BETTER BE FIXED (FOR THE SAME REASON WHY 91% WAS NOT REALISTIC ABOVE)\n","#clf = GridSearchCV(pipeline, tuned_parameters, scoring='f1_macro', cv = N_train)\n","#clf.fit(X_train, y_train)\n","#print(\"Best parameters set found on development set:\",clf.best_params_)\n","#y_pred = clf.predict(X_test)\n","#print(classification_report(y_test, y_pred))\n"],"execution_count":30,"outputs":[{"output_type":"stream","text":["N_subjects 32\n","[]\n","[]\n"],"name":"stdout"}]}]}